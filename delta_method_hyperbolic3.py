# -*- coding: utf-8 -*-
"""delta_method_hyperbolic3_v23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qtuzmODL8rY2GCervxgZ63JbO38q_asu

# Nonlinear regression using lmfit combined with using the delta method to estimate confidence intervals and prediction intervals

**An example using a 3-parameter hyperbolic function**

by Greg Pelletier (gjpelletier@gmail.com)

This script uses the python package called lmfit for nonlinear regression. We also include a new function using the delta method, to extend beyond the capabilities of lmfit, to estimate confidence intervals for predicted values, and prediction intervals for new data, using the nonlinear regression fit.

The lmfit package is used to find the best-fit values and the variance-covariance matrix of the model parameters. The user may specify any expression for the nonlinear regression model. The lmfit package is described at the following link:

https://lmfit.github.io//lmfit-py/index.html

In this example we use a 3-parameter hyperbolic function to fit a data set posted in an online forum at https://stackoverflow.com/questions/59889441/prediction-intervals-for-hyperbolic-curve-fit-scipy

To estimate the confidence intervals and prediction intervals, we use a new python function that applies the delta method. The delta method is described in detail in Section 5.1 of this online lecture:

https://jchiquet.github.io/MAP566/docs/regression/map566-lecture-nonlinear-regression.html

___

First we need to install lmfit if it is not already installed:
"""

pip install lmfit

"""Next we import the necessary python packages:"""

import matplotlib.pyplot as plt
import numpy as np
from numpy import loadtxt
from numpy import exp, linspace, sin
import lmfit as fit
from lmfit.models import ExpressionModel

"""Next we will use example observations posted in an online forum (https://stackoverflow.com/questions/59889441/prediction-intervals-for-hyperbolic-curve-fit-scipy), where x=time (days) and y=prod"""

x = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])
y = np.array([800, 900, 1200, 700, 600, 550, 500, 650, 625, 600, 550,
                 525, 500, 400, 350])

"""We will use the ExpressionModel function of lmfit to specify the 3-parameter hyperbolic function that we want to fit to our data, where the 3 parameters are qi, b, and di:"""

mod = ExpressionModel('qi/((1.0+b*di*x)**(1.0/b))')

"""The next step is to define the initial values for the parameters qi, b, and di of the model function as follows:"""

qi_init = 1000
b_init = 0.5
di_init = 0.1

"""Now we can build the set of the initial parameter values as follows:

"""

pars = fit.Parameters()
pars['qi'] = fit.Parameter(name='qi', value=qi_init, min=-np.inf, max=np.inf)
pars['b'] = fit.Parameter(name='b', value=b_init, min=-np.inf, max=np.inf)
pars['di'] = fit.Parameter(name='di', value=di_init, min=-np.inf, max=np.inf)

"""Now we are ready to run lmfit to find the best-fit parameters and variance covariance matrix of the model. The output results will be stored in "out"
"""

out = mod.fit(y, pars, x=x)

"""We can print out a summary of the model fit results as follows:"""

print(out.fit_report())

"""The best-fit values of the model parameters can now be extracted into a numpy array that we named "param" from the lmfit results as follows:"""

param=np.array(out.params)
param

"""The variance-covariance matrix of the model parameters can be extracted into a numpy array that we name "COVB" as follows:"""

COVB = out.covar
COVB

"""Now we have almost everything we need in order to estimate the confidence intervals and prediction intervals of the model. Before doing that, we need to define a function that will apply the delta method as follows:"""

def delta_method(COVB,param,x_new,f,x,y,alpha):
    # - - -
    # Function to calculate the confidence interval and prediction interval
    # for any user-defined regression function using the delta-method
    # as described in Sec 5.1 of the following online statistics lecture:
    # https://jchiquet.github.io/MAP566/docs/regression/map566-lecture-nonlinear-regression.html
    #
    # Greg Pelletier (gjpelletier@gmail.com)
    # - - -
    # INPUT
    # COVB = variance-covariance matrix of the model parameters (e.g. out.covar from lmfit)
    # param = best-fit parameters of the regression function
    # x_new = new x values to evaluate new predicted y_new values (e.g. x_new=linspace(min(x),max(x),100)
    # f = user-defined regression lambda function to predict y given inputs if param and x values (e.g. observed x or x_new)
    # 	For example, if using the 3-parameter nonlinear regression exponential threshold function, then
    # 	f = lambda param,xval : param[0] + param[1] * exp(param[2] * xval)
    # x = observed x
    # y = observed y
    # alpha = significance level for the confidence/prediction interval (e.g. alpha=0.05 is the 95% confidence/prediction interval)
    # - - -
    # OUTPUT
    # y_new = predicted y values at x_new
    # lwr_conf = lower confidence interval for each value in x_new
    # upr_conf = upper confidence interval for each value in x_new
    # lwr_pred = lower prediction interval for each value in x_new
    # upr_pred = upper prediction interval for each value in x_new
    # pvalue = signficance level of the regression from the probability of the F-test
    import numpy as np
    from scipy import stats
    # - - -
    # calculate predicted y_new at each x_new
    y_new = f(param,x_new)
    # calculate derivative gradients at x_new (change in f(x_new) per change in each param using +1ppb change in each param)
    grad_new = np.empty(shape=(np.size(x_new),np.size(param)))
    h = 1e-8       # h= small change for each param to balance truncation error and rounding error of the gradient
    for i in range(np.size(param)):
        # make a copy of param
        param2 = np.copy(param)
        # gradient forward
        param2[i] = (1+h) * param[i]
        y_new2 = f(param2, x_new)
        dy = y_new2 - y_new
        dparam = param2[i] - param[i]
        grad_up = dy / dparam
        # gradient backward
        param2[i] = (1-h) * param[i]
        y_new2 = f(param2, x_new)
        dy = y_new2 - y_new
        dparam = param2[i] - param[i]
        grad_dn = dy / dparam
        # centered gradient is the average gradient forward and backward
        grad_new[:,i] = (grad_up + grad_dn) / 2
    # calculate variance in y_new due to each parameter and for all parameters combined
    G_new = np.matmul(grad_new,COVB) * grad_new         # variance in y_new due to each param at each x_new
    GS_new = np.sum(G_new,axis=1)                       # total variance from all param values at each x_new
    # - - -
    # # lwr_conf and upr_conf are confidence intervals of the best-fit curve
    nobs = np.size(x)
    nparam = np.size(param)
    df = nobs - nparam
    qt = stats.t.ppf(1-alpha/2, df)
    delta_f = np.sqrt(GS_new) * qt
    lwr_conf = y_new - delta_f
    upr_conf = y_new + delta_f
    # - - -
    # # lwr_pred and upr_pred are prediction intervals of new observations
    yhat = f(param,x)
    SSE = np.sum((y-yhat) ** 2)                 # sum of squares (residual error)
    MSE = SSE / df                              # mean square (residual error)
    syx = np.sqrt(MSE)                          # std error of the estimate
    delta_y = np.sqrt(GS_new + MSE) * qt
    lwr_pred = y_new - delta_y
    upr_pred = y_new + delta_y
    # - - -
    # optional additional outputs of regression statistics
    SST = np.sum(y **2) - np.sum(y) **2 / nobs  # sum of squares (total)
    SSR = SST - SSE                             # sum of squares (regression model)
    MSR = SSR / (np.size(param)-1)              # mean square (regression model)
    Fstat = MSR / MSE           # F statistic
    dfn = np.size(param) - 1    # df numerator = degrees of freedom for model = number of model parameters - 1
    dfd = df                    # df denomenator = degrees of freedom of the residual = df = nobs - nparam
    pvalue = 1-stats.f.cdf(Fstat, dfn, dfd)      # p-value of F test statistic
    rsquared = SSR / SST                                                        # ordinary rsquared
    adj_rsquared = 1-(1-rsquared)*(np.size(x)-1)/(np.size(x)-np.size(param)-1)  # adjusted rsquared
    # - - -
    return y_new, lwr_conf, upr_conf, lwr_pred, upr_pred, pvalue

"""Before using the delta_method function, we first need to make a few more inputs for it as follows:"""

# model lambda function to use for any param or xval
f = lambda param,xval : param[0]/((1.0+param[1]*param[2]*xval)**(1.0/param[1]))

# evenly spaced new observations that extend from below min(x) to above max(x)
x_new = linspace(0, 20, 100)

# probability level for the prediction limits (e.g. alpha=0.05 for 95% prediction limits and 95% confidence limits)
alpha=0.05

"""Now we are ready to use the delta_method function to find the predicted y_new values, and the 95% prediction limits (lwr_pred and upr_pred), and 95% confidence limits (lwr_conf and upr_conf), at alpha=0.05 for new observations (x_new)"""

y_new, lwr_conf, upr_conf, lwr_pred, upr_pred, pvalue = delta_method(COVB,param,x_new,f,x,y,alpha)

"""Now we can plot the results of lmfit, combined with the results of the delta_method function to estimate the prediction intervals and confidence intervals."""

# make string values of fit stats and eqn for the plot labels
pstr = '%.4f' %pvalue
rsquared = out.rsquared
rsqstr = '%.4f' %rsquared
b1str = '%.1f' %param[0]
b2str = '%.4f' %param[1]
b3str = '%.5f' %param[2]
eqnstr = 'y = ' + b1str + '/((1+' + b2str + '*' + b3str + '*x)**(1/' + b2str + '))'

# generate the plot
plt.figure()
plt.plot(x, y, '.', label='observations')
# observations
plt.plot(x_new, y_new, '-', label='best fit')
# 95% prediction limits using the delta method
plt.fill_between(x_new, lwr_pred, upr_pred,color="#d3d3d3", label='95% prediction interval')
# 95% confidence limits using the delta method
plt.fill_between(x_new, lwr_conf, upr_conf,color="#ABABAB", label='95% confidence interval')
plt.legend(loc='lower left')
# plt.title('Delta-method for prediction and confidence intervals')
plt.suptitle('Delta-method for prediction and confidence intervals')
plt.title('An example of a 3-parameter hyperbolic fit')
plt.xlabel('x= time')
plt.ylabel('y= prod')
plt.text(4, 1400, eqnstr, fontsize = 10)
plt.text(4, 1300, 'r^2 = '+rsqstr+', p = '+pstr, fontsize = 10)
plt.ticklabel_format(style='plain', axis='y')
# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))